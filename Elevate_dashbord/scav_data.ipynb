{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import linemerge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = 'C:\\\\Users\\\\BPARK17\\\\OneDrive - azureford\\\\JupyterNotebooks\\\\Elevate_dashbord\\\\'\n",
    "\n",
    "SPATIAL_HOME = 'C:\\\\Users\\\\BPARK17\\\\OneDrive - azureford\\\\JupyterNotebooks\\\\Census_CitySolutions\\\\data\\\\census_areas_2020\\\\'\n",
    "\n",
    "NETWORK_HOME = 'C:\\\\Users\\\\BPARK17\\\\OneDrive - azureford\\\\JupyterNotebooks\\\\ESRI_Network\\\\'\n",
    "NETWORK_DATA = f'{NETWORK_HOME}data\\\\'\n",
    "GRID = f'{NETWORK_DATA}Grid\\\\Grid_network\\\\'\n",
    "PROJECT = 'Move'\n",
    "USECASE = f'{NETWORK_DATA}UseCase\\\\{PROJECT}\\\\'\n",
    "\n",
    "CRS = 'EPSG:4269'\n",
    "\n",
    "VOT_HOUR = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def summary_table_preprocessing(table_path, data_dict_path):\n",
    "  ## Input\n",
    "  # read data\n",
    "  data_dict_df = pd.read_csv(data_dict_path)\n",
    "  sum_raw_df = pd.read_csv(table_path, sep='delimiter', engine='python')\n",
    "\n",
    "  ## Data dictionary\n",
    "  # categorize columns by type\n",
    "  cols_int = [c for c in data_dict_df.loc[data_dict_df['data_type'].isin(['int', 'bigint'])]['col_name'].to_list() if c in sum_raw_df.columns.values[0].split(',')]\n",
    "  cols_float = [c for c in data_dict_df.loc[data_dict_df['data_type']=='double']['col_name'].to_list() if c in sum_raw_df.columns.values[0].split(',')]\n",
    "  cols_datetime = [c for c in data_dict_df.loc[data_dict_df['data_type'].isin(['timestamp'])]['col_name'].to_list() if c in sum_raw_df.columns.values[0].split(',')]\n",
    "  cols_date = [c for c in data_dict_df.loc[data_dict_df['data_type'].isin(['date'])]['col_name'].to_list() if c in sum_raw_df.columns.values[0].split(',')]\n",
    "\n",
    "  ## Summary table\n",
    "  sum_list = []\n",
    "  for rec in sum_raw_df.iterrows():\n",
    "    rec_list = rec[1].values[0].split(',')\n",
    "    if len(rec_list) > len(data_dict_df):    \n",
    "      new_rec_list = []\n",
    "      tmp_v = ''\n",
    "      append = False\n",
    "      for v in rec_list:\n",
    "        if v[0] == '[':\n",
    "          append = True\n",
    "        if v[-1] == ']':\n",
    "          append = False\n",
    "\n",
    "        tmp_v += v\n",
    "        if append == False:\n",
    "          if len(tmp_v) == 0:\n",
    "            new_rec_list.append(v)\n",
    "          else:\n",
    "            new_rec_list.append(tmp_v)\n",
    "            tmp_v = ''\n",
    "      sum_list.append(new_rec_list)\n",
    "    else:\n",
    "      sum_list.append(rec_list)\n",
    "  sum_df = pd.DataFrame(sum_list)\n",
    "  sum_df.columns = sum_raw_df.columns.to_list()[0].split(',')\n",
    "\n",
    "\n",
    "  ## Convert data type\n",
    "  for c in cols_int:\n",
    "    sum_df[c] = sum_df[c].replace('NULL', -999).astype(int)\n",
    "\n",
    "  for c in cols_float:\n",
    "    sum_df[c] = sum_df[c].replace('NULL', -999).astype(float)\n",
    "\n",
    "  for c in cols_datetime:\n",
    "    rec_list = []\n",
    "    for v in sum_df[c]:\n",
    "      try:\n",
    "        rec_list.append(datetime.datetime.strptime(v.split('.')[0], '%Y-%m-%d %H:%M:%S'))\n",
    "      except:\n",
    "        rec_list.append(datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S'))\n",
    "    sum_df[c] = rec_list\n",
    "\n",
    "  for c in cols_date:\n",
    "    rec_list = []\n",
    "    for v in sum_df[c]:\n",
    "      try:\n",
    "        rec_list.append(datetime.datetime.strptime(v, '%Y-%m-%d').date())\n",
    "      except:\n",
    "        rec_list.append(datetime.datetime.strptime('1900-01-01', '%Y-%m-%d').date())\n",
    "    sum_df[c] = rec_list\n",
    "\n",
    "  sum_df = sum_df.sort_values(by=['cvdcqa_vin_d_3', 'cvdcqa_trip_no_r_3'])\n",
    "  return sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiLineString\n",
    "from shapely.ops import linemerge, unary_union\n",
    "\n",
    "def convert_multi_to_single_line(geom):\n",
    "    if isinstance(geom, MultiLineString):\n",
    "        merged_line = linemerge(geom)\n",
    "        result = unary_union(merged_line)\n",
    "        return result[0]\n",
    "    else:\n",
    "        return geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_by_vot(gdf):\n",
    "  date_list = []\n",
    "  trip_id = 0\n",
    "  trip_vot_dict = {}\n",
    "  for rec in gdf.itertuples():\n",
    "    \n",
    "    if rec.cvdcqa_partition_date not in date_list:\n",
    "      trip_id = 0\n",
    "      date_list.append(rec.cvdcqa_partition_date)\n",
    "      \n",
    "    if f'{rec.cvdcqa_vin_d_3}_{rec.cvdcqa_partition_date}_{trip_id}' not in trip_vot_dict:\n",
    "      trip_vot_dict[f'{rec.cvdcqa_vin_d_3}_{rec.cvdcqa_partition_date}_{trip_id}'] = []\n",
    "\n",
    "    trip_vot_dict[f'{rec.cvdcqa_vin_d_3}_{rec.cvdcqa_partition_date}_{trip_id}'].append(rec)\n",
    "\n",
    "    if rec.cvdcqa_time_spnt_at_dest_in_secs_r_3 > VOT_HOUR * 3600:\n",
    "      trip_id +=1\n",
    "  out = {key:gpd.GeoDataFrame(pd.DataFrame(val), geometry='geometry', crs=CRS) for key, val in trip_vot_dict.items()}\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_routes(gdf):\n",
    "  miles = 0\n",
    "  geometry = []\n",
    "  for ind in gdf.index:\n",
    "    if ind < gdf.index.max():\n",
    "      try:\n",
    "        orig_lon = gdf.iloc[ind]['geometry'].coords[0][0]\n",
    "        orig_lat = gdf.iloc[ind]['geometry'].coords[0][1]\n",
    "        dest_lon = gdf.iloc[ind+1]['geometry'].coords[0][0]\n",
    "        dest_lat = gdf.iloc[ind+1]['geometry'].coords[0][1]\n",
    "        tot_route = sp.find_shortest_path(orig_lon, orig_lat, dest_lon, dest_lat, orig_knn=2, dest_knn=2)\n",
    "        \n",
    "        miles+=tot_route['miles']\n",
    "        geometry.append(convert_multi_to_single_line(tot_route['geometry']))\n",
    "      except:\n",
    "        continue\n",
    "  \n",
    "  new_geometry = linemerge(geometry)\n",
    "  return miles, new_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "import numpy as np\n",
    "def points_to_line(point_gdf):\n",
    "  stack_lonlat = point_gdf.agg({'cvdcqa_trip_orig_long_r_3': np.stack, 'cvdcqa_trip_orig_lat_r_3':  np.stack})\n",
    "  lineStringObj = LineString(list(zip(*stack_lonlat)))\n",
    "\n",
    "  rec_dict = {'cvdcqa_vin_d_3':[point_gdf.iloc[0]['cvdcqa_vin_d_3']],\n",
    "              'cvdcqa_trip_strt_odo_read_r_3':[point_gdf.iloc[0]['cvdcqa_trip_strt_odo_read_r_3']],\n",
    "              'cvdcqa_trip_end_odo_read_r_3':[point_gdf.iloc[-1]['cvdcqa_trip_end_odo_read_r_3']],\n",
    "              'cvdcqa_trip_strt_time_s_3':[point_gdf.iloc[0]['cvdcqa_trip_strt_time_s_3']],\n",
    "              'cvdcqa_trip_end_time_s_3':[point_gdf.iloc[-1]['cvdcqa_trip_end_time_s_3']],\n",
    "              'cvdcqa_trip_durn_in_secs_r_3':[point_gdf['cvdcqa_trip_durn_in_secs_r_3'].sum()],\n",
    "              'cvdcqa_time_spnt_at_dest_in_secs_r_3':[point_gdf.iloc[:-1]['cvdcqa_time_spnt_at_dest_in_secs_r_3'].sum()],\n",
    "              'cvdcqa_odo_chng_km_r_3':[point_gdf['cvdcqa_odo_chng_km_r_3'].sum()],\n",
    "              'cvdcqa_trip_orig_lat_r_3':[point_gdf.iloc[0]['cvdcqa_trip_orig_lat_r_3']],\n",
    "              'cvdcqa_trip_orig_long_r_3':[point_gdf.iloc[0]['cvdcqa_trip_orig_long_r_3']],\n",
    "              'cvdcqa_trip_dest_lat_r_3':[point_gdf.iloc[-1]['cvdcqa_trip_dest_lat_r_3']],\n",
    "              'cvdcqa_trip_dest_long_r_3':[point_gdf.iloc[-1]['cvdcqa_trip_dest_long_r_3']],\n",
    "              'geometry':lineStringObj\n",
    "              }\n",
    "  return gpd.GeoDataFrame(rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin_trip_straight_gdf = pd.DataFrame()\n",
    "scav_df = pd.read_csv(f'{HOME}src\\\\data\\\\scav\\\\ncvdvqaa_trip_sum_4g_na_usa_msi_vw_2023_04_12.csv')\n",
    "scav_gdf = gpd.GeoDataFrame(scav_df, geometry=gpd.points_from_xy(scav_df['cvdcqa_trip_orig_long_r_3'], scav_df['cvdcqa_trip_orig_lat_r_3']), crs=CRS)\n",
    "for vin, vin_trip_gdf in scav_gdf.groupby('cvdcqa_vin_d_3'):\n",
    "  vin_trips_dict = get_trip_by_vot(vin_trip_gdf.sort_values(by='cvdcqa_trip_strt_time_s_3'))\n",
    "  for key, val_gdf in vin_trips_dict.items():\n",
    "    val_gdf = val_gdf.loc[(val_gdf['cvdcqa_trip_orig_lat_r_3']!=-999)  & (val_gdf['cvdcqa_trip_orig_long_r_3']!=-999) & (~val_gdf['cvdcqa_trip_orig_long_r_3'].isna())]\n",
    "    if len(val_gdf) > 2:\n",
    "      vin_trip_straight_gdf = pd.concat([vin_trip_straight_gdf, points_to_line(val_gdf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BPARK17\\AppData\\Local\\Temp/ipykernel_12276/2291085618.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  vin_trip_straight_gdf.to_file(f'{HOME}src\\\\data\\\\scav\\\\test.shp')\n"
     ]
    }
   ],
   "source": [
    "vin_trip_straight_gdf.to_file(f'{HOME}src\\\\data\\\\scav\\\\test.shp')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "012d7b61900244923f021fc0e41e2568317b1b2dbcade1c07935635a800c7e15"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
